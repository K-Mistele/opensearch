/*************************************************************************************************

Welcome to Baml! To use this generated code, please run one of the following:

$ npm install @boundaryml/baml
$ yarn add @boundaryml/baml
$ pnpm add @boundaryml/baml

*************************************************************************************************/

// This file was generated by BAML: do not edit it. Instead, edit the BAML
// files and re-generate this code.
//
/* eslint-disable */
// tslint:disable
// @ts-nocheck
// biome-ignore format: autogenerated code
const fileMap = {
  
  "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\nclient<llm> GeminiFlash25 {\n  provider google-ai\n  options {\n    model \"gemini-2.5-flash\"\n    api_key env.GOOGLE_API_KEY\n  }\n}\n\nclient<llm> GeminiPro25 {\n  provider google-ai\n  options {\n    model \"gemini-2.5-pro\"\n    api_key env.GOOGLE_API_KEY\n  }\n}\n\nclient<llm> CustomGPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT4oMini {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-4o-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomSonnet {\n  provider anthropic\n  options {\n    model \"claude-3-5-sonnet-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-haiku-20240307\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT4oMini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT4oMini, CustomGPT4oMini]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  // Strategy is optional\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  // Strategy is optional\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}\n",
  "create_answer.baml": "function CreateAnswer(\n    current_date: string,\n    research_topic: string,\n    summaries: SearchResult[],\n) -> string {\n    client \"google-ai/gemini-2.5-pro\"\n    prompt #\"\n        Generate a high-quality answer to the user's question based on the provided summaries.\n\n        Instructions:\n        - The current date is {{current_date}}.\n        - You are the final step of a multi-step research process, don't mention that you are the final step. \n        - You have access to all the information gathered from the previous steps.\n        - You have access to the user's question.\n        - Generate a high-quality answer to the user's question based on the provided summaries and the user's question.\n        - To include the sources you used from the Summaries in the answer correctly, use markdown footnotes. This creates a superscript number with a link to jump to the footnote. You can put footnotes anywhere in the document except inside other markdown elements like blocks, lists, and tables. \n        - When you use a footnote, you should use the id of the summary as the footnote id - the links at the bottom of the document will be added _for you_ - there is no need to add them yourself.\n\n        <markdown_footnotes_example>\n            Here's a simple footnote,[^abc789a] and here's a longer one.[^90fdaha]\n\n            Note that the citations will be added for you - there is no need to add them yourself. They will be auto-generated like this:\n            [^abc789a]: This is the first footnote.\n\n            [^90fdaha]: Here's another footnote.\n        </markdown_footnotes_example>\n\n        Very important instructions:\n        - if the information is not sufficient, you should indicate to the user that you don't have enough information to answer the question.\n        - make sure to indicate how confident you are in the answer, and why.\n\n        User Context:\n        - {{research_topic}}\n\n        Summaries:\n        <summaries>\n        {% for summary in summaries %}\n            <summary>\n                <id>{{summary.id}}</id>\n                <title>{{summary.title}}</title>                \n                <url>{{summary.url}}</url>\n                <highlights>{{summary.highlights}}</highlights>\n                <text>{{summary.text}}</text>\n            </summary>\n        {% endfor %}\n        </summaries>\n\n        Reflect carefully on all the the summaries and the user's question to provide an answer.\n        {{ctx.output_format}}\n\n    \"#\n}\n",
  "generate_query.baml": "\n/// Generate an optimized query (or several) for web research\nfunction GenerateQuery(\n    args: GenerateQueryArgs,\n) -> SearchQueryList {\n    client \"google-ai/gemini-2.5-flash\"\n    prompt #\"\n    \n        {{ _.role(\"system\")}}\n        Your goal is to generate sophisticated and diverse web search queries. These queries are intended for an advanced automated web research tool capable of analyzing complex results, following links, and synthesizing information.\n\n        Instructions:\n        - Always prefer a single search query, only add another query if the original question requests multiple aspects or elements and one query is not enough.\n        - Each query should focus on one specific aspect of the original question.\n\n        {% if args.number_queries == 1 %}\n        - Generate 1 query.\n        {% elif args.number_queries %}\n        - Don't produce less than 2 queries.\n        - Don't produce more than {{args.number_queries}} queries.\n        {% else %}\n        - Generate a few queries\n        {% endif %}\n        - Queries should be diverse, if the topic is broad, generate more than 1 query to get sufficient coverage of different keywords and assumptions.\n        - Don't generate multiple similar queries, 1 is enough.\n        - Queries should be specific and not too broad. Make sure to include important qualifiers and modifiers.\n        - Query should ensure that the most current information is gathered. The current date is {{args.current_date}}.\n        - We are using Exa's Search API so the queries should not use google-specific search operators\n        - If the query is complicated or multi-part (e.g. about multiple different people, businesses, entities or topics), break it down into multiple queries.\n\n        The research topic is provided between <research_topic></research_topic> XML tags below.\n        <research_topic>\n        {{ args.research_topic}}\n        </research_topic>\n\n\n        <output_format>\n        {{ ctx.output_format }}\n        </output_format>\n    \"#\n}\n\n",
  "generate_query.test.baml": "test NapthaAiFunding {\n    functions [GenerateQuery]\n    args {\n        args {\n            research_topic \"What is Naptha AI's most recent funding round in terms of dollars raised and the round size? (pre-seed, seed,Series A, Series B, Series C, Series D)\"\n            current_date \"06/24/2025\"\n        }\n\n    }\n}\n\ntest ConstellateAIFunding {\n    functions [GenerateQuery]\n    args {\n       args {\n            research_topic \"What is Constellate AI's most recent funding round in terms of dollars raised and the round size? (pre-seed, seed,Series A, Series B, Series C, Series D)\"\n            number_queries 10\n            current_date: \"06/24/2025\"\n       }\n    }\n}\n\ntest HumanLayerFunding {\n    functions [GenerateQuery]\n    args {\n        args {\n            research_topic \"What is Human Layer's most recent funding round in terms of dollars raised and the round size? (pre-seed, seed,Series A, Series B, Series C, Series D)\"\n            number_queries 10\n            current_date: \"06/24/2025\"\n        }\n    }\n}   \n\ntest BoundaryMLFunding {\n    functions [GenerateQuery]\n    args {\n        args {\n            research_topic \"What is BoundaryML's most recent funding round in terms of dollars raised and the round size? (pre-seed, seed,Series A, Series B, Series C, Series D)\"\n            number_queries 10\n            current_date: \"06/24/2025\"\n        }\n    }\n}",
  "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"typescript\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.90.2\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode async\n}\n",
  "reflect.baml": "function Reflect(\n    summaries: SearchResult[],\n    research_topic: string,\n    current_date: string,\n) -> Reflection {\n    client \"google-ai/gemini-2.5-pro\"\n    prompt #\"\n    You are an expert research assistant analyzing summaries about \"{{research_topic}}\"..\n\n    The current date is {{current_date}}.\n\n    Instructions:\n    - Identify if the information provided in the summaries is sufficient to answer the user's question. \n    - If the information is sufficient, set isSufficient to true. Do not generate a follow-up query.\n    \n    If the information in the summaries is insufficient, identify knowlege gaps and write follow-up queries to address them:\n    - Identify knowledge gaps or areas that need deeper exploration and generate a follow-up query. (1 or multiple).\n    - If provided summaries are sufficient to answer the user's question, don't generate a follow-up query.\n    - Generate one or more follow-up queries that would help expand your understanding.\n    - Focus on technical details, implementation specifics, or emerging trends that weren't fully covered.\n\n    Requirements:\n    - Ensure the follow-up queries are self-contained web search queries\n    - Each should contain the necessary context AND simplicity to be used as a web search. \n    - Avoid highly complicated follow-up queries, and avoid overly-broad queries. \n\n    Follow-Up queries structuring:\n    - If the query is complicated or multi-part (e.g. about multiple different entities or topics), break it down into multiple queries.\n    - If you generate multiple queries, make sure they are diverse and not similar.\n    - Queries should be diverse, if the topic is broad, generate more than 1 query to get sufficient coverage of different keywords and assumptions.\n    - Don't generate multiple similar queries, 1 is enough.\n    - Queries should be specific and not too broad. Make sure to include important qualifiers and modifiers.\n    - We are using Exa's Search API so the queries should not use google-specific search operators\n\n\n    Summaries:\n    <summaries>\n    {% for summary in summaries %}\n        <summary>\n            <title>{{summary.title}}</title>\n            <url>{{summary.url}}</url>\n            <highlights>{{summary.highlights}}</highlights>\n            <id>{{summary.id}}</id>\n            <text>{{summary.text}}</text>\n        </summary>\n    {% endfor %}\n    </summaries>\n\n    Reflect carefully on the Summaries to identify knowledge gaps and produce a follow-up query. Then, produce your output following this JSON format:\n    {{ctx.output_format}}\n    \"#\n}",
  "types.baml": "\nclass GenerateQueryArgs {\n    research_topic string\n    current_date string\n    number_queries int?\n}\n// State management types for the research workflow\nclass SearchQueryList {\n    query string[] @description(\"A list of search queries to be used for web research.\")\n    rationale string @description(\"A brief explanation of why these queries are relevant to the research topic, addressed as though you were speaking to a user explaining what you are doing\")\n}\n\nclass Reflection {\n    isSufficient bool @description(\"Whether the provided summaries are sufficient to answer the user's question\")\n    knowledgeGap string? @description(\"A description of what information is missing or needs clarification, if isSufficient is false\")\n    followUpQueries string[]? @description(\"A list of follow-up web search queries to be researched to address the knowledge gap, if isSufficient is false\")\n    followupQueriesRationale string[]? @description(\"Your rationalee for why these follow-up queries are relevant to the research topic in the context of the knowledge gap, addressed as though you were speaking to a user explaining what you are doing (if isSufficient is false)\")\n}\n\n\nclass Message {\n    role string @description(\"The role of the message sender (e.g., 'user', 'assistant', 'system')\")\n    content string @description(\"The content of the message\")\n}\n\n\nclass ReflectionState {\n    is_sufficient bool @description(\"Whether the current information is sufficient\")\n    knowledge_gap string @description(\"Description of the knowledge gap identified\")\n    follow_up_queries string[] @description(\"Follow-up queries to address knowledge gaps\")\n    research_loop_count int @description(\"Current research loop count\")\n    number_of_ran_queries int @description(\"Number of queries that have been executed\")\n}\n\nclass Query {\n    query string @description(\"The search query string\")\n    rationale string @description(\"Rationale for why this query is needed\")\n}\n\nclass QueryGenerationState {\n    search_query Query[] @description(\"List of generated queries with rationales\")\n}\n\nclass WebSearchState {\n    search_query string @description(\"The search query to execute\")\n    id string @description(\"Unique identifier for the search\")\n}\n\nclass SearchStateOutput {\n    running_summary string? @description(\"Final report or running summary of research\")\n} \n\nclass SearchResult {\n    url string @description(\"The URL of the search result\")\n    id string @description(\"The ID of the search result\")\n    title string? | null @description(\"The title of the search result\")\n    highlights string[] @description(\"The highlights of the search result\")\n    highlightScores float[] @description(\"The highlight scores of the search result\")\n    text string @description(\"The text of the search result\")\n}",
}
export const getBamlFiles = () => {
    return fileMap;
}